\section{Problem Solution}
This project involves two sets of deliverables, a sequential version
utilizing the Dynamic algorithm for LCS, and a parallel LCS algorithm
developed by \cite{Liu:2007p402}.

\subsection{Sequential}
We investigated the single-processor, single-threaded version of an
LCS algorithm using the common Dynamic table generation
algorithm. Refer to section \ref{sec:metrics} for benchmarks recorded
for this sequential algorithm, compared against our parallelized
algorithm. This code was written in Java using the Parallel Java
libraries \cite{pj}.

The dynamic table generation algorithm is a quadratic-time
linear-space algorithm for the calculation of the length of the
longest common subsequence. The dynamic programming LCS algorithm
computes with $O(2*min(n,m))$ space and time complexity of $O(mn)$
time, where $X$ and $Y$ are two input strings and $|x| = n$ and $|y| =
m$.

\subsubsection{Algorithm Description}
The Dynamic programming algorithm operates by constructing a table,
where each cell contains the length of the longest common subsequence
up until the indices of that cell in the input sequences. As the value
of a cell solely depends on the cells above, to the left, and
diagonally from the cell, only two rows of the table need to be
maintained at any given time. The value of the cell in the last row
and column contains the length of the longest common subsequence.
 
\begin{codebox}
\Procname{$\proc{Dynamic Programming LCS-length}(m,n,A,B)$}
\li	\Comment Initialization
\li $K[1][j] \gets 0 [j=0 \twodots n]$
\li \For $i \gets 1$ \To $m$ 
\li	\Do
\li 	$K[0][j] \gets K[1][j] (j=0\twodots n)$
\li 	\For $j \gets 1$ \To $n$ 
\li		\Do
\li			\If $A[i] = B[j]$ 
\li			\Then 
\li				$K[1][j] \gets K[0][j-1] + 1$
\li			\Else
\li				$K[1][j] \gets max(K[1][j-1], K[0][j])$
			\End
		\End
	\End
\li	$LL[j] \gets K[1][j] (j=0\twodots n)$
\end{codebox}

\subsection{Parallelized}
The parallel algorithm uses a technique called \textit{wavefront
  parallelism}. The shorter sequence is initailly broken into $ k $
chunks, and each processor is made responsible for a series of
columns. Each processor is tasked with computing the values for its
column in blocks of $h$ rows. As a processor finishes computing a
block, it sends the data overlapping with its neighbor, the ``passage
band'', to the next processor, who is then able to compute a block of
values itself. Once the entire table is calculated, the answer remains
in the final processor's computation block. Refer to \ref{sec:metrics}
for the computation time, speedup, efficiency, and experimentally
determined sequential fraction values for a number of test cases.

While this technique does provide a good amount of parallelism, it
does not achieve load balancing when calculating the first $ k $
blocks and the last $ k $ blocks. This does not significantly effect
the result; however, as the block size is so small that the unbalanced
computation time is insignificant.


